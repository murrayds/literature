## Big Data, Little Data, No Data

**Keywords**:  Data Management; Disciplinary Practice; Library Science

**Authors**: Christine Borgman

**Date of Publication**: 2015

**Reference**: Borgman, C. L. (2015). Big Data, Little Data, No Data: Scholarship in the Networked World. Cambridge, Massachusetts: The MIT Press.


#### Key Concepts
----

1. **Data:** Roughly Borgman defined data as "entities used as evidence of phemonena for the purposes of research or scholarship" (pg 29) To elaborate, "entiteis becoem data only when someone uses them as evidence of a phenomenon, and the same entities can be evidence of multiple phenomena". Borgman's most inclusive summary is that "data are representations of observations, objects, or other entities used as evidence of phenomena for the purposes of research or scholarship". Borgman provides a whole chapter discussing the various definintions of data and big data, and a key feature of this chapter is just how difficult it is to provide an adequete definintion that fits the kinds of materials used by the sciences, social sciences, and humanities. 

2. **Knowledge Infrastructure:** A concept used here to provide a framework to assess social and technical interactions of data scholarship. Originally defined by Paul Edwards as "robust networks of people, artifacts, and institutions that generate, share, and maintain specific knowledge about the human and natural worlds". Borgman goes on to describe that these networks include "technology, intellectual activities, learning, collaboration, and distirbuted access to human expertise and to documented information" (pg 33). Knowledge infrastructures vary by context and community, serving the needs of each. These infrastructures are necessary to make sense of massive amounts of information, a common complaint of scholars going back to the 17th century. In the context of "data", these infrastructure include the technical infrastructure (servers, hard disks, APIs, etc.) but also social technologies (metadata schemes, standardizations, etc.) and human capital (for maintaining, contextualizing, documenting, and more).

3.  **Source and Resource:** Sources are data that originate with the investigators on a given project. Resources are existing data reused for a given project. In other words, scholars who collect their own data are collecting *sources* whereas scholars who repurposes or reuse other data are leveraging *resources*

4. **Data Scholarship:** A term coined by Borgman to frame the complex set of relations that exist between *data* and *scholarship*. This idea was originally framed as *data intensive resarch* which eventually morphed into terms like *eScience* and *cyberinfrastructure*. Data scholarship is a significant concept now because scholars, students, and others are beginning to recognize that having enough data and the right techniques to exploit them enables new questions to be asked and new forms of evidence to be obtained. However, it can be difficult to determine whether a particualr dataset is or will be valuable. 

5. **Data Policy:** Defined roughly as "the set of choices made by governments and funding agencies about matters such as what they consdier to be data; what they require researchers to savel what they require researchers to release, when, how, and to whom; what data they require to be curated, by whom, and for how long; and how these requirements are implemened in grant proposals, in awards, and in provision of data repositories." (pg 38) 


#### Questions
----

***What is the main argument of the text?***

The core concept of this book is that the value of data lies in their use. The entire book discusses the value of data in different contexts, comparing data use in the sciences, social sciences, and humanities, as well as discussing various data sharing practices, policies, and challenges. In addition to these comparisons, Borgman also outlines an extensive literature review discussing the various definintions of and perspectives on data, knowledge infrastructures, data scholarship, and more. 

The book reads like a textbook and so lacks a coherent central argument or narrative. By the end of the book, it is clear that the primary perspective of the book is one of data management. She argues that since the value of data lies in their use, that big data that is not made usable is effectively "no data". Work must be done to make data usable, to contextualize it, add metadata, process it, document it, clean it, and much more. However, this work is so often invisible and not rewarded. After disucssing various stakeholders, their incentives, and their policies, Borgman argues that unless the stakeholders find a way to reward the invisible work of data curation and archiving, that we risk losing their value.

***Describe the structure of the book's central argument***

Borgman provides a series of "provications" about data (pg 14) which she attempts to adress throughout the book. These provocations are roughly:

- Addressing issues of control, access, and ownership will determine how data's value is distributed
- Transferring knoweldge over time/distance/contexts is difficult. Same with data. But in some cases, its more difficult than in others.
- The role of publications has remained the same in spite of new data/technologies. Data serves a different purpose than do publications, and publiations are not merely containers for data. 
- Scholarly work is widley disseminated through open access, data, and software, but under differenct incentives, means, and porposes. The implications of this are poorly understood.
- Knoweldge infrastructures are evolving to accomodate new forms of ata, access, technologies, and policy; csts and benefits are being re-distributed; new expertise is needed in certain contexts and domains
- Knowledge infrastructures adapt only in the long-term, over generations of scholars

The book itself is largely repsonding to these provocations. The layout of the text is in three distinct parts,

The first part serves as an extended literature review, summarizing the current scholarship on the definintions, qualities, and characteristics of data, data schoalrship, and knoweldge infrastructures.

The second part moves on to present 6 case studies on the use and value of data in specific scholarly context, 2 for the sciences, 2 for the social sciences, and 2 for the humanities. For the sciences she focuses on data in the centralized and standarized field of Astronomy and the much more heterogeneous Sensor-Networked science and Technology. For the social sciences, she outlines the characteristics of data in internst surveys and social media, whereas the second case study concerns how information technologies are developed, designed, and used in science and technology research at the Center for Embedded Network Sensing. Finally, Borgman how a highly collaborative team of classicists and archaeologists create a technology test bef ffor cultural heritage sites; in constrast to this environment, Borgman also presents the case of scholarship in Buddhist Studies, wherin long scholars piece together items from digital collections with physical texts and artefacts. 

For each of these case studies, Borgman discusses the characteirstics of data as they relate to the following items,

- Size Matters: What is the scale of data in this context? (in respect to volume, velocity, variety, etc.). How is it collected and analyzed? Is is cleaned and processed, and if so, by who? What processes and tools dictate how it is analyzed?
- When are data: When is the material of interest counted as "data"? For example, if taking field notes, when exactly do these cross the threshold from "notes" to "data"? How close or distant is the schoalr from the data? How is contextualization handled in this context?
- Sources and Resources: What kinds of data are collected by the scholars themselves, as compared to that which is re-used? How is reuse facilitated (or not) within the context, and who does the work of contextualization?
- Metadata: Is metadata necessary, and if so, how much? (this relates back to the "how distant is the scholar" point). How is this metadata added? What kinds of metadata are necessary? Are there any communiteis and standards dictating metadata format?
- Provenance: How is the lifecycle of data tracked and considered? Is there some sort of version control system? Is the data used typically raw, or processed in some way?
- Economics and Values: What are the economic costs and benefits of the data in this context? What is the value of the data (apart from economic value)? Is schoalrship in this context typically cooperative, or competative, and how does this affect the use and sharing of data?
- Property rights: How are rights to data treated in this context? Is it owned by anyone, and if so, whom?
- Ethical: What ethical issues permeate the storage, use, and sharing of data in this domain? Is the data sensitive? Are there protocols or processes for handling ethical issues of data?

The final section of the book first applies the same analytical categories of above to data sharing and policy more generally. Here and through the rest of the book, the focus shifts almost entirely to data management. borgman discusses various data policy and stakeholders, discussing the challenges of each. She also discusses more in-depth data sharing, data citation, data publishing, and more. In particualr, Borgman focuses on the work that is necesary to effectively curate and archive data and the fact that this work is largely invisable and goes unrewarded. Borgman closes with a summarization of previous topics as well as a call-to-action for better policy and knowledge infrastructure to make data more usable and to invest and credit the invisible work necessary to do so. 

***Describe the main literatures that the text draws on and contributes to, and the particular contribution made by the text.***

This text largely sits within the field of Data Management and Information Technology Management. More generally, it fits within library and informaiton science. Indeed, Borgman cites scholars like Bowker and Star many times throughout. Borgman also draws on work that sits more generally in Science and Technology Studies such as Paul Edward's *A Vast Machine* and Star & Griesemer's work on *boundary objects*. Towards the end, Borgman even touches on scientometrics.

This text contributes mostly to the field of Data Management, providing a fairly simple introduction to many concepts related to the use of data in different contexts. Borgman's goal seems to be to contribute to ongoing debates in policy regarding data openess and sharing. These contributions largely seem to be in the scholarly domain of data management, rather than commercial or public domains. 

***Describe the methodology (or methodologies) used in the text, and how it enables the author(s) to support the text’s main argument.***

There is a diffent sort of methodology used for each section of the book. The first section is largely an overview of the field. Borgman follows a narrative review format, citing various research, and reads much the same as a really long literature review in a paper. 

The second section focuses on applying some of the cited ideas towards understnading actual case studies. Borgman cites a total of 6 case studies of various contexts in the sciences, social sciences, and humanities. These case studies serve as practical examples of how data's use and value differs base on context. 

The final part of the book moves back towards a lit-review style, through this time focusing on data policy and management. Borgman provides some examples of policies in practice, but the chapter is largely focused on ideas rather than practical examples. 

***What quotes capture the critical significance of the text?***

"Policies of governments, funding agencies, journals, and institutions that are intended to impove the flow of scholarly communication often make simplifying assumptions about the ability to commodify and exchange information. While usually intended to promote equity across communities and disciplines, policies that fail to respect the substantial differences in theory, practice, and culture between fields are likely to be implemented poorly, be counterproductive, or be ignored by their constituents, Individual communities may have their own moral economices that govern how data are collected, managed, and shared" (pg 38)

"The policies of funding agencies, journals, and other stakeholders in data scholarship have focused on increasing the supply of data available for reuse with minimal attention to scholarly motivations for sharing or reusing data or to the knowledge infrastructure investments required. The rationales for promoting data sharing reflect the legitimate concerns of stakeholders such as the ability to reproduce research, make public assets available to the public, leverage investments in research, and advance research and innovation. These rationales often lead to generic policies that fail to reflect the vast diveristy of data scholarship within and between domains. Data are both assets and liabilities. When research depend on the ability to reuse one's own data and to pool those data with researchers within the community, incentives exist to release and reuse data. When research is local and exploratory or when research depends on evidence accumulated over long periods of time, incentives to release are few" (pg 237-238)

"Data are not natural objects that can be readily commodified and exchanged in a marketplace. They are entities used as evidence of phenomena. The same observations and objects can be represented in many ways. As a consequence, the same entity often becomes different in many ways. As a consequence, the same entity often becomes different data when transferred to another context. Slight changes in interpretation, method, or practice can result in those entities being assessed as slightly different evidence of somewhat different phenomena. Decisions made in the earliest stages of the research, such as preprocessing done before observations are considered data, richoet through the remainder of the process" (pg 238)

"Despite an overall lack of agreement, most scholars would like better means to manage whatever they do consider to be their data. Better management is likely to lead to more sustainable data and in turn better means of discovering and sharing data These are expensive investmenets that cannot fall on the shoulders of scholars alone. better access to data requires investmenets in knowledge infrastructures by research communities, funding agencies, universities, publishers, and other stakeholders. Technology, policy, and practice intersect in many ways. Knitting together the many moving parts of knowledge infrastructures requires investment in the people who hold those parts together through their invisible work" (pg 287)





Its somehwat long and tedious, also somewhat redundant. Howver, I still think it provides a pretty good introduction and overview of data and data management policies. 
